{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d8009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'https://mirror.coggle.club/dataset/coggle-competition/'\n",
    "train_data = pd.read_csv(data_dir + 'intent-classify/train.csv', sep='\\t', header=None)\n",
    "test_data = pd.read_csv(data_dir + 'intent-classify/test.csv', sep='\\t', header=None)\n",
    "cn_stopwords = pd.read_csv('https://mirror.coggle.club/stopwords/baidu_stopwords.txt', header=None)[0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7ee70",
   "metadata": {},
   "source": [
    "# 任务4：词向量训练与使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9c252",
   "metadata": {},
   "source": [
    "词向量是一种将单词转化为向量表示的技术，在自然语言处理中被广泛应用。通过将单词映射到一个低维向量空间中，词向量可以在一定程度上捕捉到单词的语义信息和关联关系，进而提高自然语言处理任务的性能。以下是使用词向量进行文本分类的一个简单示例：\n",
    "\n",
    "- 步骤1：使用结巴对文本进行分词，结巴是一个基于Python的中文分词工具，并支持自定义字典和停用词。\n",
    "- 步骤2：使用gensim训练词向量，也可以考虑加载已有的预训练词向量。gensim是一个基于Python的自然语言处理库，可以方便地训练或加载词向量，并进行相似度计算、最近邻查询等操作。\n",
    "- 步骤3：使用词向量对单词进行编码，然后计算句子向量（可以直接求词向量均值）。将每个单词替换为其对应的词向量后，得到一个由多个向量组成的矩阵。为了简化计算和降低维度，可以对矩阵按行求均值，得到一个代表句子含义的句子向量。\n",
    "- 步骤4：使用LR、SVM和决策树对句子向量进行训练，验证和预测。LR（逻辑回归）、SVM（支持向量机）和决策树都是常用的机器学习分类算法，可以使用sklearn库中提供的相关函数来实现。\n",
    "- 步骤5：通过上述步骤，请回答下面问题\n",
    "    - 词向量的维度会影响到模型精度吗？一般来说，词向量的维度越高，则表示单词语义信息和关联关系的能力越强；但同时也会增加计算复杂度和过拟合风险。\n",
    "    - 词向量编码后使用树模型和LR，谁的精度高，为什么？这个问题没有确定性答案，可能取决于数据集特征、参数设置、随机因素等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b10325b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in d:\\python\\envs\\torch\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in d:\\python\\envs\\torch\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in d:\\python\\envs\\torch\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: six>=1.5.0 in d:\\python\\envs\\torch\\lib\\site-packages (from gensim) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in d:\\python\\envs\\torch\\lib\\site-packages (from gensim) (6.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c05d32",
   "metadata": {},
   "source": [
    "### doc2vec\n",
    "\n",
    "doc2vec，是一种用于将文档嵌入到向量空间中的算法。doc2vec是对word2vec的扩展，它可以将整个文档转换为一个向量，而不是仅仅将文档中的单词转换为向量。\n",
    "\n",
    "doc2vec使用的是分布式记忆（distributed memory）和分布式袋子（distributed bag of words）两种方法之一来生成文档向量。在分布式记忆方法中，doc2vec通过在词向量和文档向量之间添加额外的文档特定权重向量，来将每个文档映射到一个向量。在分布式袋子方法中，doc2vec将整个文档视为一个“袋子”，并将其表示为单词的总体统计信息。\n",
    "\n",
    "在gensim中使用doc2vec通常包括以下步骤：\n",
    "\n",
    "1. 准备文本数据，包括分词和预处理。\n",
    "2. 创建一个doc2vec模型对象，并设置一些参数，例如向量维度和训练次数等。\n",
    "3. 使用模型对象对文档进行训练，以生成每个文档的向量表示。\n",
    "4. 对生成的向量进行可视化或用于其他任务，例如分类或聚类。\n",
    "使用doc2vec可以将文档转换为向量表示，这有助于在文档级别进行语义相似性计算、文档分类和聚类等任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15849e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40167b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00405157 -0.00423348  0.00235998 -0.00344383 -0.00189501  0.00232245\n",
      " -0.00333223  0.00183112  0.00229583 -0.00205365  0.00037681 -0.00244087\n",
      "  0.00240427 -0.00298053 -0.00269047 -0.00231196  0.0047758   0.0005443\n",
      "  0.003554   -0.00119127  0.00282145  0.00052725  0.00153015 -0.00364587\n",
      " -0.00353337 -0.00256159 -0.00280384 -0.00103318 -0.00239896 -0.00225912\n",
      "  0.00170294  0.00261734 -0.00041167 -0.00377863  0.0046927  -0.00422551\n",
      "  0.00103848  0.00270509  0.00318679  0.00183495  0.002868   -0.00467838\n",
      " -0.00354228  0.00439599  0.00277557  0.00077657 -0.00303043 -0.00089328\n",
      " -0.00070813  0.00174617 -0.00255878 -0.00401057  0.00357092 -0.00410191\n",
      "  0.00122982  0.00182956 -0.00176973  0.00455286 -0.00067492  0.00324289\n",
      " -0.00400212 -0.00444271  0.00477241  0.00026583  0.00272923  0.00431652\n",
      "  0.00459398  0.00253583  0.00392726 -0.00355168  0.00165042  0.0034133\n",
      "  0.00436443 -0.00130036 -0.00138304  0.0025451  -0.00275112  0.00421641\n",
      " -0.00162318  0.00358855 -0.00115857  0.0032651   0.00192545  0.00476265\n",
      " -0.00025226  0.00243307 -0.00350945  0.00037335  0.00105376  0.00465802\n",
      "  0.00268799 -0.00067078  0.00312454 -0.00488011 -0.00203581  0.00429351\n",
      " -0.00102602 -0.00331102  0.00092153  0.00038262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\torch\\lib\\site-packages\\gensim\\models\\base_any2vec.py:742: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'], \n",
    "             ['this', 'is', 'the', 'second', 'sentence'], \n",
    "             ['yet', 'another', 'sentence'], \n",
    "             ['one', 'more', 'sentence'], \n",
    "             ['and', 'the', 'final', 'sentence']]\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "\n",
    "## Prints the word vector for the word 'sentence'\n",
    "print(model.wv['sentence']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63bdd9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06074138  0.03846406  0.05704906  0.08301251 -0.03915465]\n"
     ]
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "\n",
    "## Print the inferred vector for the given sentence\n",
    "print(model.infer_vector(['this', 'is', 'a', 'test'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b14794c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['双鸭山', '淮阴', '汽车票', '13', '号'], ['回家'], ['随便', '播放', '一首', '专辑', '阁楼', '佛里', '歌'], ['墓', '王之王'], ['想', '挑战', '两把', 's686', '突变', '团', '竞', '游戏', '视频'], ['想', '和平', '精英', '战神', '必备', '技巧', '游戏', '视频'], ['2019', '古装', '爱情', '电视剧', '小女', '花不弃', '花絮', '播放'], ['找', '一个', '2004', '推理', '剧给', '一会'], ['自驾游', '深圳', '都', '地方'], ['转播', '女子双打', '乒乓球', '比赛', '现场']]\n",
      "12100\n",
      "[TaggedDocument(words=['双鸭山', '淮阴', '汽车票', '13', '号'], tags=['Travel-Query']), TaggedDocument(words=['回家'], tags=['Travel-Query']), TaggedDocument(words=['随便', '播放', '一首', '专辑', '阁楼', '佛里', '歌'], tags=['Music-Play']), TaggedDocument(words=['墓', '王之王'], tags=['FilmTele-Play']), TaggedDocument(words=['想', '挑战', '两把', 's686', '突变', '团', '竞', '游戏', '视频'], tags=['Video-Play']), TaggedDocument(words=['想', '和平', '精英', '战神', '必备', '技巧', '游戏', '视频'], tags=['Video-Play']), TaggedDocument(words=['2019', '古装', '爱情', '电视剧', '小女', '花不弃', '花絮', '播放'], tags=['Video-Play']), TaggedDocument(words=['找', '一个', '2004', '推理', '剧给', '一会'], tags=['FilmTele-Play']), TaggedDocument(words=['自驾游', '深圳', '都', '地方'], tags=['Travel-Query']), TaggedDocument(words=['转播', '女子双打', '乒乓球', '比赛', '现场'], tags=['Video-Play'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\torch\\lib\\site-packages\\gensim\\models\\base_any2vec.py:742: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12100\n"
     ]
    }
   ],
   "source": [
    "# jieba切词并去除停用词\n",
    "content = train_data[0].tolist()\n",
    "\n",
    "# 读取中文停用词\n",
    "cn_stopwords = ' '.join(pd.read_csv('https://mirror.coggle.club/stopwords/baidu_stopwords.txt', header=None)[0])\n",
    "corpus = []\n",
    "for cont in content:\n",
    "    words = []\n",
    "    word = jieba.lcut(cont)\n",
    "    for x in word:\n",
    "        if x not in cn_stopwords:\n",
    "            words.append(x)\n",
    "    corpus.append(words)\n",
    "\n",
    "print(corpus[:10])\n",
    "\n",
    "\n",
    "docs = [TaggedDocument(doc, [label]) for doc, label in zip(corpus, train_data[1])]\n",
    "print(len(docs))\n",
    "print(docs[:10])\n",
    "\n",
    "\n",
    "# 创建一个Doc2Vec模型实例\n",
    "model = Doc2Vec(documents=docs, vector_size=100, window=5, min_count=2, epochs=100)\n",
    "\n",
    "# 训练模型\n",
    "model.train(docs, total_examples=len(docs), epochs=model.epochs)\n",
    "\n",
    "# 获取文档向量\n",
    "train_doc2vec = []\n",
    "for doc in docs:\n",
    "    # 注意：这里使用的是infer_vector()方法，因为它可以用于未知文档的向量表示\n",
    "    train_doc2vec.append(list(model.infer_vector(doc.words)))\n",
    "    \n",
    "print(len(train_doc2vec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aab047cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- 交叉验证 ------------- \n",
      "KNN\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Alarm-Update       0.92      0.73      0.82      1264\n",
      "           Audio-Play       0.42      0.54      0.47       226\n",
      "       Calendar-Query       0.88      0.92      0.90      1214\n",
      "        FilmTele-Play       0.57      0.86      0.69      1355\n",
      "HomeAppliance-Control       0.81      0.94      0.87      1215\n",
      "           Music-Play       0.71      0.84      0.77      1304\n",
      "                Other       0.63      0.40      0.49       214\n",
      "         Radio-Listen       0.85      0.70      0.77      1285\n",
      "       TVProgram-Play       0.71      0.13      0.22       240\n",
      "         Travel-Query       0.90      0.82      0.86      1220\n",
      "           Video-Play       0.87      0.70      0.77      1334\n",
      "        Weather-Query       0.94      0.87      0.90      1229\n",
      "\n",
      "             accuracy                           0.79     12100\n",
      "            macro avg       0.77      0.70      0.71     12100\n",
      "         weighted avg       0.81      0.79      0.79     12100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Alarm-Update       0.91      0.88      0.89      1264\n",
      "           Audio-Play       0.69      0.40      0.51       226\n",
      "       Calendar-Query       0.88      0.93      0.90      1214\n",
      "        FilmTele-Play       0.74      0.78      0.76      1355\n",
      "HomeAppliance-Control       0.86      0.88      0.87      1215\n",
      "           Music-Play       0.80      0.85      0.83      1304\n",
      "                Other       0.72      0.49      0.58       214\n",
      "         Radio-Listen       0.79      0.79      0.79      1285\n",
      "       TVProgram-Play       0.68      0.45      0.54       240\n",
      "         Travel-Query       0.85      0.86      0.86      1220\n",
      "           Video-Play       0.79      0.79      0.79      1334\n",
      "        Weather-Query       0.89      0.90      0.90      1229\n",
      "\n",
      "             accuracy                           0.83     12100\n",
      "            macro avg       0.80      0.75      0.77     12100\n",
      "         weighted avg       0.83      0.83      0.82     12100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Alarm-Update       0.90      0.89      0.89      1264\n",
      "           Audio-Play       0.75      0.37      0.49       226\n",
      "       Calendar-Query       0.88      0.94      0.91      1214\n",
      "        FilmTele-Play       0.75      0.77      0.76      1355\n",
      "HomeAppliance-Control       0.87      0.90      0.88      1215\n",
      "           Music-Play       0.80      0.85      0.82      1304\n",
      "                Other       0.75      0.47      0.58       214\n",
      "         Radio-Listen       0.80      0.78      0.79      1285\n",
      "       TVProgram-Play       0.66      0.40      0.50       240\n",
      "         Travel-Query       0.85      0.87      0.86      1220\n",
      "           Video-Play       0.78      0.79      0.79      1334\n",
      "        Weather-Query       0.89      0.91      0.90      1229\n",
      "\n",
      "             accuracy                           0.83     12100\n",
      "            macro avg       0.81      0.75      0.77     12100\n",
      "         weighted avg       0.83      0.83      0.83     12100\n",
      "\n",
      "Tree\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "         Alarm-Update       0.49      0.46      0.47      1264\n",
      "           Audio-Play       0.08      0.08      0.08       226\n",
      "       Calendar-Query       0.56      0.52      0.54      1214\n",
      "        FilmTele-Play       0.37      0.39      0.38      1355\n",
      "HomeAppliance-Control       0.53      0.52      0.53      1215\n",
      "           Music-Play       0.47      0.49      0.48      1304\n",
      "                Other       0.13      0.14      0.13       214\n",
      "         Radio-Listen       0.41      0.41      0.41      1285\n",
      "       TVProgram-Play       0.07      0.08      0.07       240\n",
      "         Travel-Query       0.54      0.55      0.55      1220\n",
      "           Video-Play       0.40      0.40      0.40      1334\n",
      "        Weather-Query       0.58      0.59      0.58      1229\n",
      "\n",
      "             accuracy                           0.46     12100\n",
      "            macro avg       0.39      0.39      0.39     12100\n",
      "         weighted avg       0.46      0.46      0.46     12100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_pred = cross_val_predict(\n",
    "    KNeighborsClassifier(),\n",
    "    train_doc2vec,\n",
    "    train_data[1]\n",
    ")\n",
    "\n",
    "print('------------- 交叉验证 ------------- ')\n",
    "print('KNN')\n",
    "print(classification_report(train_data[1], cv_pred))\n",
    "\n",
    "cv_pred = cross_val_predict(\n",
    "    LogisticRegression(),\n",
    "    train_doc2vec,\n",
    "    train_data[1]\n",
    ")\n",
    "print('LR')\n",
    "print(classification_report(train_data[1], cv_pred))\n",
    "\n",
    "cv_pred = cross_val_predict(\n",
    "    LinearSVC(),\n",
    "    train_doc2vec,\n",
    "    train_data[1]\n",
    ")\n",
    "\n",
    "print(\"SVM\")\n",
    "print(classification_report(train_data[1], cv_pred))\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cv_pred = cross_val_predict(\n",
    "    DecisionTreeClassifier(),\n",
    "    train_doc2vec,\n",
    "    train_data[1]\n",
    ")\n",
    "\n",
    "print(\"Tree\")\n",
    "print(classification_report(train_data[1], cv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24e7ab",
   "metadata": {},
   "source": [
    "- 使用词向量的交叉验证效果 没有tfidf效果好，可能是和文本长度有关\n",
    "- 树模型效果较差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4a685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
