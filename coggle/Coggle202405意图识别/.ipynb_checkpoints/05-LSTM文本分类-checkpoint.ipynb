{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef412d5",
   "metadata": {},
   "source": [
    "# 任务：LSTM意图分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3616a57",
   "metadata": {},
   "source": [
    "LSTM（Long Short-Term Memory）是一种特殊的循环神经网络，在文本分类任务中表现良好。LSTM可以通过对输入文本进行序列建模来捕捉文本中的长期依赖关系，并对文本进行分类。\n",
    "\n",
    "- 步骤1：搭建LSTM模型，具体结构为Embedding层、LSTM层和全连接层；\n",
    "    - Embedding层：将输入的文本转换为词向量表示，降低维度并保留语义信息；\n",
    "    - LSTM层：使用长短期记忆单元处理词向量序列，学习文本中的上下文信息，并输出隐藏状态；\n",
    "    -全连接层：将LSTM层的最后一个隐藏状态作为特征输入，使用softmax函数输出每个类别的概率。\n",
    "- 步骤2：使用任务3中的词向量初始化Embedding层\n",
    "- 步骤3：LSTM模型的训练，验证和预测\n",
    "- 步骤4：通过上述步骤，请回答下面问题\n",
    "    - Embedding层的精度与初始化方式相关吗？\n",
    "    - LSTM模型精度与文本最大长度是否相关？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd2b1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b2866",
   "metadata": {},
   "source": [
    "# 一. 数据处理\n",
    "## 1.1 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1196e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = 'https://mirror.coggle.club/dataset/coggle-competition/'\n",
    "train_data = pd.read_csv(data_dir + 'intent-classify/train.csv', sep='\\t', header=None)\n",
    "test_data = pd.read_csv(data_dir + 'intent-classify/test.csv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a69ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0              1\n",
      "0         还有双鸭山到淮阴的汽车票吗13号的   Travel-Query\n",
      "1                   从这里怎么回家   Travel-Query\n",
      "2          随便播放一首专辑阁楼里的佛里的歌     Music-Play\n",
      "3                 给看一下墓王之王嘛  FilmTele-Play\n",
      "4     我想看挑战两把s686打突变团竞的游戏视频     Video-Play\n",
      "5       我想看和平精英上战神必备技巧的游戏视频     Video-Play\n",
      "6  2019年古装爱情电视剧小女花不弃的花絮播放一下     Video-Play\n",
      "7        找一个2004年的推理剧给我看一会呢  FilmTele-Play\n",
      "8            自驾游去深圳都经过那些地方啊   Travel-Query\n",
      "9        给我转播今天的女子双打乒乓球比赛现场     Video-Play\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "27ec18d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Other', 'Video-Play', 'Travel-Query', 'Audio-Play', 'TVProgram-Play', 'Music-Play', 'Radio-Listen', 'Alarm-Update', 'FilmTele-Play', 'Calendar-Query', 'HomeAppliance-Control', 'Weather-Query'}\n",
      "{'Other': 0, 'Video-Play': 1, 'Travel-Query': 2, 'Audio-Play': 3, 'TVProgram-Play': 4, 'Music-Play': 5, 'Radio-Listen': 6, 'Alarm-Update': 7, 'FilmTele-Play': 8, 'Calendar-Query': 9, 'HomeAppliance-Control': 10, 'Weather-Query': 11}\n",
      "{0: 'Other', 1: 'Video-Play', 2: 'Travel-Query', 3: 'Audio-Play', 4: 'TVProgram-Play', 5: 'Music-Play', 6: 'Radio-Listen', 7: 'Alarm-Update', 8: 'FilmTele-Play', 9: 'Calendar-Query', 10: 'HomeAppliance-Control', 11: 'Weather-Query'}\n"
     ]
    }
   ],
   "source": [
    "# label2idx, idx2label\n",
    "labels = train_data[1].tolist()\n",
    "all_labels = set(labels)\n",
    "print(all_labels)\n",
    "\n",
    "labels2idx = {val: key for key, val in enumerate(all_labels)}\n",
    "idx2labels = {key: val for key, val in enumerate(all_labels)}\n",
    "\n",
    "print(labels2idx)\n",
    "print(idx2labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac831b",
   "metadata": {},
   "source": [
    "## 1.2 构造Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6e5ee345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, labels2idx, do_train=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.labels2idx = labels2idx\n",
    "        self.do_train = do_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        input_ids = self.text_to_index(text)\n",
    "        if self.do_train:\n",
    "            label = self.labels2idx[self.labels[idx]]\n",
    "            return input_ids, label\n",
    "        else:\n",
    "            return input_ids\n",
    "\n",
    "    def text_to_index(self, text):\n",
    "        return [self.vocab[token] for token in jieba.lcut(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "25082c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[0].tolist()\n",
    "y_train = train_data[1]\n",
    "x_test = test_data[0].tolist()\n",
    "\n",
    "\n",
    "# 构建词汇表\n",
    "vocab = {}\n",
    "for text in x_train + x_test:\n",
    "    for token in jieba.lcut(text):\n",
    "        if token not in vocab:\n",
    "            vocab[token] = len(vocab)\n",
    "            \n",
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "86d89a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train, vocab, labels2idx, do_train=True)\n",
    "test_dataset = CustomDataset(x_test, None, vocab, labels2idx, do_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d1502e",
   "metadata": {},
   "source": [
    "## 1.3 封装DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d6a97873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 DataLoader\n",
    "# 定义 DataLoader\n",
    "def collate_fn(batch):\n",
    "    batch_input_ids, batch_labels = zip(*batch)\n",
    "    max_length = max(len(input_ids) for input_ids in batch_input_ids)\n",
    "    padded_input_ids = [input_ids + [0] * (max_length - len(input_ids)) for input_ids in batch_input_ids]\n",
    "    return torch.tensor(padded_input_ids), torch.tensor(batch_labels)\n",
    "\n",
    "\n",
    "def collate_fn_test(batch):\n",
    "    batch_input_ids = batch\n",
    "    max_length = max(len(input_ids) for input_ids in batch_input_ids)\n",
    "    padded_input_ids = [input_ids + [0] * (max_length - len(input_ids)) for input_ids in batch_input_ids]\n",
    "    return torch.tensor(padded_input_ids)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "38b816b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([9, 10, 11, 12], 2)\n",
      "[21, 27, 123, 4351, 3241, 4, 193]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1])\n",
    "print(test_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4ea49",
   "metadata": {},
   "source": [
    "# 2. 搭建LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f905810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = lstm_out[:, -1, :]  # 使用最后一个时刻的隐藏状态作为输出\n",
    "        \n",
    "        output = self.fc(lstm_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9a518f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'Other', 'Video-Play', 'Travel-Query', 'Audio-Play', 'TVProgram-Play', 'Music-Play', 'Radio-Listen', 'Alarm-Update', 'FilmTele-Play', 'Calendar-Query', 'HomeAppliance-Control', 'Weather-Query'}\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = len(set(all_labels))  # 输出类别数量\n",
    "print(output_dim)\n",
    "print(all_labels)\n",
    "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c2571e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2902b",
   "metadata": {},
   "source": [
    "## 3. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f0ea4e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houhailun\\AppData\\Local\\Temp\\ipykernel_6204\\4230932848.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(inputs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2727646979352661\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(inputs))\n",
    "#         print(outputs)\n",
    "#         print(labels)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfeca93",
   "metadata": {},
   "source": [
    "## 4. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "46e0ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houhailun\\AppData\\Local\\Temp\\ipykernel_6204\\241651478.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       text  y_pred\n",
      "0              回放CCTV2的消费主张       8\n",
      "1                 给我打开玩具房的灯      10\n",
      "2            循环播放赵本山的小品相亲来听       3\n",
      "3  15号上午10点带孩子去海洋馆的行程帮我制定下。       7\n",
      "4                把智能扫地机器人关掉      10\n",
      "5               帮我续播16集摩天大楼       8\n",
      "6             放美国电影史密斯夫妇给我看       8\n",
      "7                放刘禹锡的浪淘沙来听       5\n",
      "8             查看6月6日是农历几月几号       9\n",
      "9           放一个讲述美食的美国纪录片来看       1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        inputs = torch.tensor(inputs)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.extend(predicted.tolist())\n",
    "\n",
    "df = pd.DataFrame(zip(test_data[0], y_pred))\n",
    "df.columns = ['text', 'y_pred']\n",
    "print(df.head(10))\n",
    "df.to_csv('lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fc967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
