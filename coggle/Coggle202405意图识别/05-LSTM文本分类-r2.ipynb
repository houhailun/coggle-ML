{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ba9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = 'https://mirror.coggle.club/dataset/coggle-competition/'\n",
    "train_data = pd.read_csv(data_dir + 'intent-classify/train.csv', sep='\\t', header=None)\n",
    "test_data = pd.read_csv(data_dir + 'intent-classify/test.csv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ddcfa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>还有双鸭山到淮阴的汽车票吗13号的</td>\n",
       "      <td>Travel-Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>从这里怎么回家</td>\n",
       "      <td>Travel-Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>随便播放一首专辑阁楼里的佛里的歌</td>\n",
       "      <td>Music-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>给看一下墓王之王嘛</td>\n",
       "      <td>FilmTele-Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我想看挑战两把s686打突变团竞的游戏视频</td>\n",
       "      <td>Video-Play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0              1\n",
       "0      还有双鸭山到淮阴的汽车票吗13号的   Travel-Query\n",
       "1                从这里怎么回家   Travel-Query\n",
       "2       随便播放一首专辑阁楼里的佛里的歌     Music-Play\n",
       "3              给看一下墓王之王嘛  FilmTele-Play\n",
       "4  我想看挑战两把s686打突变团竞的游戏视频     Video-Play"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c228ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95d58f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11226    0\n",
      "8696     1\n",
      "8308     2\n",
      "6112     3\n",
      "1434     1\n",
      "4153     1\n",
      "11804    4\n",
      "9178     5\n",
      "11057    6\n",
      "10213    3\n",
      "Name: 1, dtype: int64\n",
      "Index(['Audio-Play', 'Travel-Query', 'Calendar-Query', 'Video-Play',\n",
      "       'HomeAppliance-Control', 'Alarm-Update', 'Weather-Query',\n",
      "       'Radio-Listen', 'Music-Play', 'FilmTele-Play', 'Other',\n",
      "       'TVProgram-Play'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Pandas.factorize()是Pandas模块提供的一种数据编码方式，它将每个类别数据转换成一个整数(从0开始)，有助于进行数据分析和建模。\n",
    "train_data[1], lbl = pd.factorize(train_data[1])\n",
    "\n",
    "print(train_data[1].head(10))  # 已经转换成了整数\n",
    "print(lbl)  # 去重后的标签列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46af102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coustom_data_iter(texts, labels):\n",
    "    for x, y in zip(texts, labels):\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e267c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object coustom_data_iter at 0x000001703A793200>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = coustom_data_iter(train_data[0].values[:], train_data[1].values[:])\n",
    "\n",
    "train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09019c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install torchtext\n",
    "\n",
    "# 相关参考\n",
    "# https://www.cnblogs.com/Fortunater/p/16971419.html\n",
    "\n",
    "# 构建词典\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = jieba.lcut\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)\n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c289bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '的', '我', '一下', '播放', '是', '吗', '给', '帮', '一个']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看词典(字典形式)\n",
    "vocab.get_stoi()\n",
    "# {'dog': 3,'<unk>': 0, 'kidding': 5, 'cat': 1, 'ball': 4, 'The': 2, 'like': 6, 'mat': 7, 'on': 8, 'played': 9}\n",
    "\n",
    "# 查看字典(列表形式)\n",
    "vocab.get_itos()[:10]\n",
    "# ['<unk>', '的', '我', '一下', '播放', '是', '吗', '给', '帮', '一个']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a3908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 41, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word to id\n",
    "vocab(['我', '今天', '一下'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2813e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到text切词后对应的id\n",
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db9cb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 41, 262,  32, 663])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text = torch.tensor(text_pipeline('今天我们在这里'), dtype=torch.int64)\n",
    "\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663eb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe01eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 同一批数据的长度填充\n",
    "# 90%的文本长度都在20个单词以内\n",
    "def collate_batch(batch, max_len=20):\n",
    "    label_list, text_list = [], []\n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(_label)\n",
    "        \n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        \n",
    "#         pad 参数用于指定填充的数量，其格式为 [before, after]，其中 before 表示在张量的前面填充的值的数量，\n",
    "# after 表示在张量的后面填充的值的数量。\n",
    "# pad=[0, max_len] 表示在张量的前面不填充任何值，在张量的后面填充 max_len 个值。\n",
    "# 这种填充的效果是，在张量的末尾添加了 max_len 个值为 0 的元素。\n",
    "        processed_text = F.pad(processed_text, pad=[0, max_len], mode='constant', value=0)\n",
    "        if len(processed_text) > max_len:\n",
    "            processed_text = processed_text[:max_len]\n",
    "        \n",
    "        text_list.append(processed_text)\n",
    "    \n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    \n",
    "    # 填充一个可变长度的张量列表。将长度较短的序列填充为和最长序列相同的长度。\n",
    "    # 将填充后的序列列表堆叠成一个张量\n",
    "    text_list = pad_sequence(text_list).T\n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f946e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BILSTM(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_size):\n",
    "        super(BILSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        # self.embeddings.weight.data.copy_(torch.from_numpy(pretrained_w2v))\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, bidirectional=True)\n",
    "        self.hidden2label = torch.nn.Linear(hidden_dim*2, label_size)\n",
    "        \n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # torch.Size([16, 20])\n",
    "        # print(sentence.shape)\n",
    "        sentence = torch.transpose(sentence, 1, 0)\n",
    "        \n",
    "        # batch_size在后\n",
    "        # torch.Size([20, 16])\n",
    "        # print(sentence.shape)\n",
    "        \n",
    "        # torch.Size([20, 16, 100])\n",
    "        x = self.embeddings(sentence)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # 5 seqence length\n",
    "        # 3 batch size\n",
    "        # 10 input size\n",
    "        # input = torch.randn(5, 3, 10)\n",
    "\n",
    "        lstm_out, self.hidden = self.lstm(x)\n",
    "        # torch.Size([20, 16, 128])\n",
    "        # print(lstm_out.shape)\n",
    "        y = self.hidden2label(lstm_out[-1,:,:])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01cd6600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2,3,1))\n",
    "print(a.shape)\n",
    "\n",
    "# transpose()一次只能在两个维度见进行转换，比如下面转置0维和2维\n",
    "print(torch.transpose(torch.rand((2,3,1)), 0, 2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4761cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    \n",
    "    for idx, (label, text) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        \n",
    "        predicted_label = model(text)\n",
    "        \n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()  # bp\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.1)\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        # argmax(1)：取列表每行的最大值\n",
    "        # argmax(0): 取列表每列的最大值\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        \n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c01cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(lbl)\n",
    "vocab_size = len(vocab)\n",
    "emsize = 100\n",
    "model = BILSTM(vocab_size, emsize, 64, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a63167c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# 超参数\n",
    "EPOCHS = 40\n",
    "LR = 2\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5.0, gamma=0.75)\n",
    "total_accu = None\n",
    "\n",
    "train_iter = coustom_data_iter(train_data[0].values[:], train_data[1].values[:])\n",
    "\n",
    "# 将迭代器转化为 Dataset 类型\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "\n",
    "# 切分为训练集、验证集\n",
    "num_train = int(len(train_dataset) * 0.75)\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0401259d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (label, text) in train_dataloader:\n",
    "    break\n",
    "    \n",
    "model(text).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5918c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\houhailun\\AppData\\Local\\Temp\\ipykernel_48468\\1417882319.py:14: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| end of epoch   1 | time:  5.05s | valid accuracy    0.208 \n",
      "| end of epoch   2 | time:  4.93s | valid accuracy    0.467 \n",
      "| end of epoch   3 | time:  5.04s | valid accuracy    0.649 \n",
      "| end of epoch   4 | time:  5.22s | valid accuracy    0.600 \n",
      "| end of epoch   5 | time:  5.06s | valid accuracy    0.765 \n",
      "| end of epoch   6 | time:  5.12s | valid accuracy    0.793 \n",
      "| end of epoch   7 | time:  5.27s | valid accuracy    0.816 \n",
      "| end of epoch   8 | time:  5.28s | valid accuracy    0.818 \n",
      "| end of epoch   9 | time:  5.15s | valid accuracy    0.821 \n",
      "| end of epoch  10 | time:  5.20s | valid accuracy    0.824 \n",
      "| end of epoch  11 | time:  5.07s | valid accuracy    0.829 \n",
      "| end of epoch  12 | time:  5.13s | valid accuracy    0.836 \n",
      "| end of epoch  13 | time:  5.11s | valid accuracy    0.836 \n",
      "| end of epoch  14 | time:  5.22s | valid accuracy    0.841 \n",
      "| end of epoch  15 | time:  5.20s | valid accuracy    0.836 \n",
      "| end of epoch  16 | time:  5.32s | valid accuracy    0.834 \n",
      "| end of epoch  17 | time:  5.09s | valid accuracy    0.837 \n",
      "| end of epoch  18 | time:  4.86s | valid accuracy    0.837 \n",
      "| end of epoch  19 | time:  4.96s | valid accuracy    0.840 \n",
      "| end of epoch  20 | time:  4.98s | valid accuracy    0.832 \n",
      "| end of epoch  21 | time:  4.91s | valid accuracy    0.842 \n",
      "| end of epoch  22 | time:  4.92s | valid accuracy    0.835 \n",
      "| end of epoch  23 | time:  4.94s | valid accuracy    0.838 \n",
      "| end of epoch  24 | time:  5.01s | valid accuracy    0.835 \n",
      "| end of epoch  25 | time:  4.91s | valid accuracy    0.824 \n",
      "| end of epoch  26 | time:  4.98s | valid accuracy    0.836 \n",
      "| end of epoch  27 | time:  5.26s | valid accuracy    0.837 \n",
      "| end of epoch  28 | time:  5.25s | valid accuracy    0.835 \n",
      "| end of epoch  29 | time:  5.22s | valid accuracy    0.834 \n",
      "| end of epoch  30 | time:  5.14s | valid accuracy    0.838 \n",
      "| end of epoch  31 | time:  5.15s | valid accuracy    0.836 \n",
      "| end of epoch  32 | time:  5.10s | valid accuracy    0.836 \n",
      "| end of epoch  33 | time:  5.16s | valid accuracy    0.837 \n",
      "| end of epoch  34 | time:  5.06s | valid accuracy    0.833 \n",
      "| end of epoch  35 | time:  5.01s | valid accuracy    0.835 \n",
      "| end of epoch  36 | time:  5.03s | valid accuracy    0.834 \n",
      "| end of epoch  37 | time:  5.26s | valid accuracy    0.834 \n",
      "| end of epoch  38 | time:  4.99s | valid accuracy    0.835 \n",
      "| end of epoch  39 | time:  5.02s | valid accuracy    0.833 \n",
      "| end of epoch  40 | time:  4.95s | valid accuracy    0.833 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    \n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a8749cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = coustom_data_iter(test_data[0].values[:], [0] * len(test_data))\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e0ae09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            predicted_label = model(text).argmax(1)\n",
    "            test_pred += list(predicted_label.cpu().numpy())\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8dfdba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = predict(test_dataloader)\n",
    "test_pred = [lbl[x] for x in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcf24eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'ID': range(1, len(test_pred) + 1),\n",
    "    'Target': test_pred,\n",
    "}).to_csv('nlp_submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071b35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
