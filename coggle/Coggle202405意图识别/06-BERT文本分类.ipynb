{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52dd6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354c8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'https://mirror.coggle.club/dataset/coggle-competition/'\n",
    "train_data = pd.read_csv(data_dir + 'intent-classify/train.csv', sep='\\t', header=None)\n",
    "test_data = pd.read_csv(data_dir + 'intent-classify/test.csv', sep='\\t', header=None)\n",
    "\n",
    "# train_data = train_data.sample(frac=1.0)\n",
    "train_data[1], lbl = pd.factorize(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fe15fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6dd6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>还有双鸭山到淮阴的汽车票吗13号的</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>从这里怎么回家</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>随便播放一首专辑阁楼里的佛里的歌</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>给看一下墓王之王嘛</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我想看挑战两把s686打突变团竞的游戏视频</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0  1\n",
       "0      还有双鸭山到淮阴的汽车票吗13号的  0\n",
       "1                从这里怎么回家  0\n",
       "2       随便播放一首专辑阁楼里的佛里的歌  1\n",
       "3              给看一下墓王之王嘛  2\n",
       "4  我想看挑战两把s686打突变团竞的游戏视频  3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b3ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0932d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集\n",
    "# stratity 按照标签进行采用，训练集和验证集同分布\n",
    "x_train, x_test, train_label, test_label = train_test_split(train_data[0].values,\n",
    "                                                           train_data[1].values,\n",
    "                                                           test_size=0.2,\n",
    "                                                           stratify=train_data[1].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f6ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9680 2420\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76176de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据长度分布\n",
    "train_data[0].apply(len).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d842d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids：字的编码\n",
    "# token_type_ids：标识是第一个句子还是第二个句子\n",
    "# attention_mask：标识是不是填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "918b0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")\n",
    "\n",
    "train_encoding = tokenizer(list(x_train), truncation=True, padding=True, max_length=30)\n",
    "test_encoding = tokenizer(list(x_test), truncation=True, padding=True, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a017c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集读取\n",
    "class NewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    # 读取单个样本\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = NewDataset(train_encoding, train_label)\n",
    "test_dataset = NewDataset(test_encoding, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a69f14c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 8123, 2399, 1762,  704, 1744, 1920, 7355, 3064, 1139, 4638, 1220,\n",
       "         4035, 7478,  782, 1507, 5314, 2769, 3064, 3123,  671,  678,  102,    0,\n",
       "            0,    0,    0,    0,    0,    0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(3)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb94c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 精度计算\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf9ed0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70f2b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, train_loader, epoch):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    iter_num = 0\n",
    "    total_iter = len(train_loader)\n",
    "    for batch in train_loader:\n",
    "        # 正向传播\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # 反向梯度信息\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 参数更新\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        iter_num += 1\n",
    "        if(iter_num % 100 == 0):\n",
    "            print(\"epoth: %d, iter_num: %d, loss: %.4f, %.2f%%\" % (epoch, iter_num, loss.item(), iter_num/total_iter*100))\n",
    "\n",
    "    print(\"Epoch: %d, Average training loss: %.4f\" % (epoch, total_train_loss/len(train_loader)))\n",
    "    \n",
    "    \n",
    "def validation(model, val_dataloader):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    for batch in val_dataloader:\n",
    "        with torch.no_grad():\n",
    "            # 正常传播\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"Accuracy: %.4f\" % (avg_val_accuracy))\n",
    "    print(\"Average testing loss: %.4f\" % (total_eval_loss/len(val_dataloader)))\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c13f36cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2420  2421  2422 ... 12097 12098 12099]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-macbert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "D:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoth: 0, iter_num: 100, loss: 1.8835, 4.13%\n",
      "epoth: 0, iter_num: 200, loss: 1.2772, 8.26%\n",
      "epoth: 0, iter_num: 300, loss: 0.4238, 12.40%\n",
      "epoth: 0, iter_num: 400, loss: 0.2282, 16.53%\n",
      "epoth: 0, iter_num: 500, loss: 0.1145, 20.66%\n",
      "epoth: 0, iter_num: 600, loss: 0.8303, 24.79%\n",
      "epoth: 0, iter_num: 700, loss: 0.0293, 28.93%\n",
      "epoth: 0, iter_num: 800, loss: 0.1446, 33.06%\n",
      "epoth: 0, iter_num: 900, loss: 2.4097, 37.19%\n",
      "epoth: 0, iter_num: 1000, loss: 0.0235, 41.32%\n",
      "epoth: 0, iter_num: 1100, loss: 1.2528, 45.45%\n",
      "epoth: 0, iter_num: 1200, loss: 0.0311, 49.59%\n",
      "epoth: 0, iter_num: 1300, loss: 1.5675, 53.72%\n",
      "epoth: 0, iter_num: 1400, loss: 0.5717, 57.85%\n",
      "epoth: 0, iter_num: 1500, loss: 0.0080, 61.98%\n",
      "epoth: 0, iter_num: 1600, loss: 0.0213, 66.12%\n",
      "epoth: 0, iter_num: 1700, loss: 1.5874, 70.25%\n",
      "epoth: 0, iter_num: 1800, loss: 0.0215, 74.38%\n",
      "epoth: 0, iter_num: 1900, loss: 1.3465, 78.51%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 37\u001b[0m\n\u001b[0;32m     32\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(optim,\n\u001b[0;32m     33\u001b[0m                                             num_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# Default value in run_glue.py\u001b[39;00m\n\u001b[0;32m     34\u001b[0m                                             num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     validation(model, val_dataloader)\n\u001b[0;32m     40\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(fold) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, epoch)\u001b[0m\n\u001b[0;32m     12\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1562\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1574\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    534\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    535\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 537\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    542\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    549\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 550\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:463\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    462\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 463\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Python\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 交叉验证\n",
    "kf = KFold(n_splits=5)\n",
    "flod = 0\n",
    "for train_idx, val_idx in kf.split(train_data[0].values, train_data[1].values):\n",
    "    print(train_idx)\n",
    "    train_text = train_data[0].iloc[train_idx]\n",
    "    val_text = train_data[0].iloc[val_idx]\n",
    "    \n",
    "    train_label = train_data[1].iloc[train_idx].values\n",
    "    val_label = train_data[1].iloc[train_idx].values\n",
    "    \n",
    "    train_encoding = tokenizer(list(train_text), truncation=True, padding=True, max_length=30)\n",
    "    val_encoding = tokenizer(list(val_text), truncation=True, padding=True, max_length=30)\n",
    "    \n",
    "    # 默认是没有数据扩增，文本默认是没有变换的操作\n",
    "    train_dataset = NewDataset(train_encoding, train_label)\n",
    "    val_dataset = NewDataset(val_encoding, val_label)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 加载每折的模型\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('hfl/chinese-macbert-base', num_labels=12)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 优化方法\n",
    "    optim = AdamW(model.parameters(), lr=1e-5)\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                                num_warmup_steps=0,  # Default value in run_glue.py\n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_loader, epoch)\n",
    "        validation(model, val_dataloader)\n",
    "\n",
    "    torch.save(model.state_dict(), 'model_' + str(fold) + '.pt')\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559674b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "\n",
    "test_encoding = tokenizer(list(test_data[0]), truncation=True, padding=True, max_length=30)\n",
    "test_dataset = NewsDataset(test_encoding, [0] * len(test_data))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "def prediction(model, test_dataloader):\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    for batch in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            # 正常传播\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        pred.append(logits)\n",
    "        # pred += list(np.argmax(logits, axis=1).flatten())\n",
    "\n",
    "    return np.vstack(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b521e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((3000, 12))\n",
    "for path in ['model_0.pt', 'model_1.pt', 'model_2.pt', 'model_3.pt', 'model_4.pt']:\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    pred += prediction(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame({\n",
    "    'ID': range(1, len(test_data) + 1),\n",
    "    'Target': [lbl[x] for x in pred.argmax(1)],\n",
    "}).to_csv('nlp_submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
