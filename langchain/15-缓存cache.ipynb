{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76105001",
   "metadata": {},
   "source": [
    "# 缓存（Cache）\n",
    "对于大量的重复需求，其实我们可以通过缓存来提高效率，因为某些LLM请求需要花费大量时间进行处理，甚至还会花费你的大量token，也可以在一定程度上解决某些LLM服务限频请求的问题。\n",
    "\n",
    "- 缓存的命中方式可以使用精准匹配、相似度匹配、语义匹配等\n",
    "\n",
    "- 缓存的存储方式可以基于内存、SQLite、Redis和自定义的SQLAlchemy\n",
    "\n",
    "接下来我们逐一介绍各种缓存方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3e3fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'question_tokens': 1, 'prompt_tokens': 1, 'completion_tokens': 8, 'total_tokens': 9}}, id='run-f3d8d406-3e57-4486-ac32-db2392d318d9-0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用第三方模型\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_community.chat_models import ChatSparkLLM\n",
    "\n",
    "# 科大讯飞 LLM\n",
    "spark_appid = os.environ['spark_appid']\n",
    "spark_api_secret = os.environ['spark_api_secret']\n",
    "spark_api_key = os.environ['spark_api_key']\n",
    "\n",
    "\n",
    "llm = ChatSparkLLM(\n",
    "    spark_app_id=spark_appid, spark_api_key=spark_api_key, spark_api_secret=spark_api_secret\n",
    ")\n",
    "\n",
    "llm.invoke('你好')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbdaeb",
   "metadata": {},
   "source": [
    "## 1. 内存缓存\n",
    "内存缓存适合于短暂的缓存需求，当内存达到一定限制时，缓存将被删除。\n",
    "\n",
    "使用内存缓存的好处是速度非常快，缓存可以在很短时间内访问到。\n",
    "\n",
    "以下使用了InMemoryCache来实现内存缓存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817ee0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# 定义缓存方式\n",
    "langchain.llm_cache = InMemoryCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02d77d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 172 ms\n",
      "Wall time: 1.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么我可以帮忙的吗？', response_metadata={'token_usage': {'question_tokens': 1, 'prompt_tokens': 1, 'completion_tokens': 7, 'total_tokens': 8}}, id='run-7022197d-b64e-40d0-847b-0f746022f9c7-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time llm.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4f00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 996 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么我可以帮忙的吗？', response_metadata={'token_usage': {'question_tokens': 1, 'prompt_tokens': 1, 'completion_tokens': 7, 'total_tokens': 8}}, id='run-7022197d-b64e-40d0-847b-0f746022f9c7-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time llm.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d96c18",
   "metadata": {},
   "source": [
    "> 发现同一个问题，第二次请求模型耗时极少，直接在缓存中查找"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210441a4",
   "metadata": {},
   "source": [
    "## 2. SQLite缓存\n",
    "当缓存过大时，SQLite是一种更好的缓存选择，对于可能需要延长持久性的缓存数据，SQLite能够提供更好的支持。\n",
    "\n",
    "以下使用了SQLiteCache来实现SQLite缓存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba317894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "langchain.llm_cache = SQLiteCache(database_path='./langchain.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68660367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 172 ms\n",
      "Wall time: 5.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='您好，我是讯飞星火认知大模型，由科大讯飞构建的认知智能大模型。\\n我旨在通过深度学习和自然语言处理技术，与人类进行流畅的交流、提供信息服务和智能解答，以满足各种领域内的认知智能需求。我的存在不仅体现了人工智能领域的前沿进展，也代表了科技为人类生活带来便利和提升的不懈努力。', response_metadata={'token_usage': {'question_tokens': 2, 'prompt_tokens': 2, 'completion_tokens': 75, 'total_tokens': 77}}, id='run-1c2f3c7f-92c9-48c3-a8ea-fe5232b1528e-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time llm.invoke(\"你是谁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4eafdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='您好，我是讯飞星火认知大模型，由科大讯飞构建的认知智能大模型。\\n我旨在通过深度学习和自然语言处理技术，与人类进行流畅的交流、提供信息服务和智能解答，以满足各种领域内的认知智能需求。我的存在不仅体现了人工智能领域的前沿进展，也代表了科技为人类生活带来便利和提升的不懈努力。', response_metadata={'token_usage': {'question_tokens': 2, 'prompt_tokens': 2, 'completion_tokens': 75, 'total_tokens': 77}}, id='run-1c2f3c7f-92c9-48c3-a8ea-fe5232b1528e-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time llm.invoke(\"你是谁\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd667ce",
   "metadata": {},
   "source": [
    "## 3.Redis缓存\n",
    "Redis提供了内存缓存和持久化缓存。Redis的启动非常快速，并且可以存储大量数据。\n",
    "\n",
    "以下使用了RedisCache来实现Redis缓存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a513276c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'redis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# We can do the same thing with a Redis cache\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 在运行此示例之前，请确保您的本地Redis实例首先运行\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mredis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Redis\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RedisCache\n\u001b[0;32m      6\u001b[0m langchain\u001b[38;5;241m.\u001b[39mllm_cache \u001b[38;5;241m=\u001b[39m RedisCache(redis_\u001b[38;5;241m=\u001b[39mRedis())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'redis'"
     ]
    }
   ],
   "source": [
    "# We can do the same thing with a Redis cache\n",
    "# 在运行此示例之前，请确保您的本地Redis实例首先运行\n",
    "from redis import Redis\n",
    "from langchain.cache import RedisCache\n",
    "\n",
    "langchain.llm_cache = RedisCache(redis_=Redis())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff21a16",
   "metadata": {},
   "source": [
    "## 4.基于语义的缓存\n",
    "基于语义的缓存可以根据已缓存文本的语义与新要缓存的文本语义进行比较，以确定是否缓存数据。\n",
    "\n",
    "以下使用了RedisSemanticCache来实现基于语义的缓存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\py310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.cache import RedisSemanticCache\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"D:/code/models/M3E/xrunda/m3e-base\")\n",
    "\n",
    "langchain.llm_cache = RedisSemanticCache(\n",
    "    redis_url='', \n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319267f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
