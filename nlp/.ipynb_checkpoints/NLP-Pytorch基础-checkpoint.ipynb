{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础层介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "TimeGPT                  D:\\Python\\envs\\TimeGPT\n",
      "baichuan                 D:\\Python\\envs\\baichuan\n",
      "py2                      D:\\Python\\envs\\py2\n",
      "py310                    D:\\Python\\envs\\py310\n",
      "so-vits-svc              D:\\Python\\envs\\so-vits-svc\n",
      "torch                 *  D:\\Python\\envs\\torch\n",
      "root                     D:\\Python\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数大小\n",
    "# input:\n",
    "#     输入大小是三维tensor[seq_len, batch_size, input_dim]\n",
    "#     seq_len: 句子的最大长度 或者 每组训练数据的时间长度\n",
    "#     input_dim: 输入的维度 或者 数据的特征数\n",
    "\n",
    "# \n",
    "# h0：\n",
    "#    输入大小是三维tensor（num_layers*directions，batch_size，hidden_size）\n",
    "rnn = nn.RNN(\n",
    "    input_size=10, \n",
    "    hidden_size=20, \n",
    "    num_layers=2, \n",
    "    bidirectional=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "# 5 seqence length\n",
    "# 3 batch size\n",
    "# 10 input size\n",
    "input = torch.randn(5, 3, 10)\n",
    "print(input.shape)\n",
    "\n",
    "\n",
    "output, hn = rnn(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 输入顺序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，RNN输入的是序列，一次把批次的所有句子都输入到RNN中，因此hiddle和output也是三维的\n",
    "\n",
    "每个时间步输入到RNN模块的维度是[batch_size, input_dim]\n",
    "\n",
    "把seq_len放在第一位的好处是，可以同时处理每个句子：\n",
    "1. 第一个时间步，输入所有句子的第一个单词 或者 第一个时间步上的所有特征\n",
    "2. 第二个时间步，输入所有句子的第二个单词 或者 第二个时间步上的所有特征\n",
    "...\n",
    "3.以此类推，直到seq_len个时间步全部输入完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN的输出变量\n",
    "\n",
    "#### output\n",
    "    RNN模型在每个时间步的输出的张量，形状取决于输入数据的形状、RNN的参数设置以及输入序列的长度。\n",
    "\n",
    "    具体来说，`output`张量的形状为`( batch_size, sequence_length, num_directions * hidden_size)`，其中：\n",
    "\n",
    "- `sequence_length`是输入序列的长度，即时间步的数量。\n",
    "- `batch_size`是输入数据的批次大小，即一次处理多少个序列。\n",
    "- `num_directions`是一个可选的参数，如果你的RNN是双向的（`bidirectional=True`），则`num_directions`为2；如果是单向的，则为1。\n",
    "- `hidden_size`是RNN的隐藏状态大小，即每个时间步的隐藏状态向量的维度。\n",
    "\n",
    "        这个`output`张量包含了RNN在每个时间步的输出。通常，你可以在训练后对这些输出进行进一步处理，例如用于分类、回归或序列到序列的任务，或者用于获得序列中的某些信息。\n",
    "\n",
    "#### h_n 最后一个时间步的输出 \n",
    "\n",
    "    此外，`torch.nn.RNN`还返回一个包含最后一个时间步的隐藏状态的张量，通常称为`h_n`。这个张量的形状为`(num_layers * num_directions, batch_size, hidden_size)`，其中：\n",
    "\n",
    "- `num_layers`是RNN模型的层数。\n",
    "- `num_directions`是一个可选的参数，如果你的RNN是双向的，则`num_directions`为2；如果是单向的，则为1。\n",
    "- `hidden_size`是RNN的隐藏状态大小，即每个时间步的隐藏状态向量的维度。\n",
    "\n",
    "        `h_n`张量包含了每个层的最后一个时间步的隐藏状态，可以用于进行额外的处理或者作为下一个时间步的初始隐藏状态。\n",
    "\n",
    "        综上所述，`output`和`h_n`是`torch.nn.RNN`模块的两个主要输出，它们提供了RNN在输入序列上的输出信息和最终的隐藏状态信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn = nn.LSTM(input_size=10, \n",
    "              hidden_size=20, \n",
    "              num_layers=2)\n",
    "\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn = nn.GRU(input_size=10, \n",
    "              hidden_size=20, \n",
    "              num_layers=2)\n",
    "\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8517,  0.3146, -0.4182],\n",
       "         [-1.2109,  0.3488,  0.6808],\n",
       "         [ 0.8797,  0.6647,  0.4363],\n",
       "         [-1.1474, -1.0755,  0.6982]],\n",
       "\n",
       "        [[ 0.8797,  0.6647,  0.4363],\n",
       "         [-0.7848,  0.6703, -0.5447],\n",
       "         [-1.2109,  0.3488,  0.6808],\n",
       "         [-0.6671,  0.7456,  1.0401]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an Embedding module containing 10 tensors of size 3\n",
    "# num_embeddings：词典的大小尺寸，比如总共出现5000个词，那就输入5000。此时index为（0-4999）\n",
    "# embedding_dim：m嵌入向量的维度，即用多少维来表示一个符号\n",
    "embedding = nn.Embedding(num_embeddings=10, \n",
    "                         embedding_dim=3)\n",
    "\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "embedding(input)\n",
    "# input shape: [2, 4, 3]\n",
    "# 每行表示一个数字的embedding向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.2247, -0.4837,  0.4901],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.3420,  2.0672, -0.0243]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example with padding_idx\n",
    "# padding_idx表示需要填充的词索引，默认0，意思是把每个input中的索引为idx的词的embed置为0\n",
    "embedding = nn.Embedding(10, 3, padding_idx=0)\n",
    "input = torch.LongTensor([[0, 2, 0, 5]])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "        [-1.3636, -0.6373, -0.3953],\n",
       "        [ 0.8767, -1.5321, -1.7318]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of changing `pad` vector\n",
    "padding_idx = 0\n",
    "embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
    "embedding.weight\n",
    "with torch.no_grad():\n",
    "    embedding.weight[padding_idx] = torch.ones(3)\n",
    "embedding.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbeddingBag\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag\n",
    "\n",
    "Computes sums or means of ‘bags’ of embeddings, without instantiating the intermediate embeddings. For bags of constant length, no per_sample_weights, no indices equal to padding_idx, and with 2D inputs, this class\n",
    "\n",
    "- with mode=\"sum\" is equivalent to Embedding followed by torch.sum(dim=1),\n",
    "- with mode=\"mean\" is equivalent to Embedding followed by torch.mean(dim=1),\n",
    "- with mode=\"max\" is equivalent to Embedding followed by torch.max(dim=1).\n",
    "\n",
    "input (Tensor) – Tensor containing bags of indices into the embedding matrix.\n",
    "\n",
    "offsets (Tensor, optional) – Only used when input is 1D. offsets determines the starting index position of each bag (sequence) in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4147,  0.4959, -2.3814],\n",
       "        [-1.2412,  0.9358,  0.6643]], grad_fn=<EmbeddingBagBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an EmbeddingBag module containing 10 tensors of size 3\n",
    "embedding_sum = nn.EmbeddingBag(10, 3, mode='sum')\n",
    "\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.tensor([1,2,4,5,4,3,2,9], dtype=torch.long)\n",
    "offsets = torch.tensor([0, 4], dtype=torch.long)\n",
    "\n",
    "embedding_sum(input, offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察输出：应该是通过offset来控制sum的边界，把前4个的每个词的emb向量求sum，后4个的每个词的emb向量求sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.8568, -0.8295, -0.3004],\n",
       "        [-0.0642,  0.2780,  0.9792]], grad_fn=<EmbeddingBagBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with padding_idx\n",
    "embedding_sum = nn.EmbeddingBag(10, 3, mode='sum', padding_idx=2)\n",
    "\n",
    "input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9], dtype=torch.long)\n",
    "offsets = torch.tensor([0,3, 6], dtype=torch.long)\n",
    "\n",
    "embedding_sum(input, offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['The', 'dog', 'ate', 'the', 'apple'], ['DET', 'NN', 'V', 'DET', 'NN']),\n",
       " (['Everybody', 'read', 'that', 'book'], ['NN', 'V', 'DET', 'NN'])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 把单词转换为id\n",
    "word_to_ix = {}\n",
    "\n",
    "for sent, tags in training_data:\n",
    "#     print(sent)\n",
    "#     print(tags)\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "            \n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each tag with a unique index\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim)\n",
    "        \n",
    "        # 线性层\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embedding(sentence)\n",
    "\n",
    "        # 因为LSTM的input shape：[seq_len, batch_size, input_dim]\n",
    "#         (seq_len, embedding_dim) -> [seq_len, batch_size, embedding_dim]\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        \n",
    "        # ( 1, sequence_length, hidden_size) -》 (seq_len, hidden_size)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        \n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[-1.3716, -0.8594, -1.1304],\n",
      "        [-1.3318, -0.8797, -1.1360],\n",
      "        [-1.4187, -0.8491, -1.1082],\n",
      "        [-1.4662, -0.8074, -1.1296],\n",
      "        [-1.4931, -0.7918, -1.1322]])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(inputs)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0352, -4.2743, -3.8784],\n",
      "        [-4.0797, -0.0243, -4.9451],\n",
      "        [-3.4386, -4.9927, -0.0397],\n",
      "        [-0.0471, -4.0156, -3.5777],\n",
      "        [-5.0312, -0.0081, -6.4522]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
